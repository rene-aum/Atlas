{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dashboard Liderazgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjbsIueYbXS5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from_drive = True  # same flag you use everywhere\n",
        "\n",
        "if os.environ.get(\"ATLAS_BOOTSTRAPPED\") != \"1\":\n",
        "    # ---------- GIT ON COLAB ONLY ----------\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "\n",
        "        git_token = userdata.get('gitToken')\n",
        "        git_user = userdata.get('gitUser')\n",
        "        git_url = f'https://{git_token}@github.com/rene-aum/Atlas.git'\n",
        "        branch_to_pull = 'dev'\n",
        "\n",
        "        os.chdir('/content')\n",
        "\n",
        "        if not os.path.isdir('Atlas'):\n",
        "            !git clone {git_url}\n",
        "\n",
        "        %cd Atlas\n",
        "        !git fetch origin {branch_to_pull}\n",
        "        !git checkout {branch_to_pull}\n",
        "        !git pull origin {branch_to_pull}\n",
        "\n",
        "        !pip install -r PipelinesConsumo/src/requirements.txt\n",
        "        %cd PipelinesConsumo\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print('Running in other environment not colab probably!')\n",
        "\n",
        "    # ---------- DRIVE + SHEETS ----------\n",
        "    if from_drive:\n",
        "        from pydrive2.auth import GoogleAuth\n",
        "        from pydrive2.drive import GoogleDrive\n",
        "        from google.colab import auth\n",
        "        from oauth2client.client import GoogleCredentials\n",
        "        import gspread\n",
        "        from google.auth import default\n",
        "        from gspread_dataframe import set_with_dataframe\n",
        "        import gdown\n",
        "\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        drive = GoogleDrive(gauth)\n",
        "\n",
        "        creds, _ = default()\n",
        "        gc = gspread.authorize(creds)\n",
        "\n",
        "    os.environ[\"ATLAS_BOOTSTRAPPED\"] = \"1\"\n",
        "else:\n",
        "    print(\"Bootstrap already done, assuming orchestrator ran it.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7Wr-CoYvsLD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import pytz\n",
        "# from matplotlib.ticker import FuncFormatter\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "sys.path.append('../..')\n",
        "from utils.utils import (get_dates_dataframe,\n",
        "                       add_year_week,\n",
        "                       custom_read,\n",
        "                       process_columns,\n",
        "                       remove_accents)\n",
        "from PipelinesConsumo.src.rawAtlas import RawAtlas\n",
        "from PipelinesConsumo.src.processedAtlas import ProcessedAtlas\n",
        "from src.transformed import Transformed\n",
        "from utils.drive_toolbox import(from_drive_to_local,\n",
        "                             get_last_modification_date_drive,\n",
        "                             create_sheets_in_drive_folder,\n",
        "                             update_sheets_in_drive_folder,\n",
        "                             read_from_google_sheets,\n",
        "                             list_file_ids_for_drive_folder,\n",
        "                             create_csv_file_in_drive_folder,\n",
        "                             write_csv_to_drive,\n",
        "                             read_csv_from_drive)\n",
        "from utils.utils import get_dates_dataframe\n",
        "from src.constants import (atlas_raw_output_folder_id,\n",
        "                           atlas_consumo_output_folder_id,\n",
        "                           consumo_sheets_ids_dict,\n",
        "                           data_source_folder_id,\n",
        "                           raw_output_ids,\n",
        "                           folder_id_bauto_gabo,\n",
        "                           id_reporte_ventas,\n",
        "                           id_torre_de_control,\n",
        "                           )\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consumo_sheets_ids_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcVentas'])\n",
        "cancelaciones = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcPublicacionesCanceladas'])\n",
        "publicaciones = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcPublicaciones'])\n",
        "pedidos = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcPedidos'])\n",
        "visitas_unicas = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcVisitasUnicas'])\n",
        "adobe_vendedor_total = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcAdobeFunnelVendedorTotal'])\n",
        "adobe_comprador_total = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcAdobeFunnelCompradorTotal'])\n",
        "clientes = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcClientes'])\n",
        "business_case_df = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcBusinessCase26'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load insumos apis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  folder_id_catalogos = \"1TE24Yl4lQ6ZxHJSw_ZDzb6W4XpB-21FL\"\n",
        "  id_catalogos_status = list_file_ids_for_drive_folder(drive,folder_id_catalogos)['CatalogoSolicitudesAprobacion']\n",
        "  cat_tarea_actual = (read_from_google_sheets(gc,id_catalogos_status,sheetname='CatTareaActual')\n",
        "                      .assign(tareaactual = lambda x: x.nb_tarea_actual.apply(remove_accents).str.strip().str.upper(),\n",
        "                              status_automarket = lambda x: x.status_am.apply(remove_accents).str.strip().str.upper())\n",
        "                      .drop(columns=['nb_tarea_actual','status_am'])\n",
        "                      )\n",
        "  cat_decision_sistema = (read_from_google_sheets(gc,id_catalogos_status,sheetname='CatDecisionSistema')\n",
        "                        .assign(decisionsistema = lambda x: x.decisionsistema.apply(remove_accents).str.strip().str.upper(),\n",
        "                                status_riesgos = lambda x: x.riesgos.apply(remove_accents).str.strip().str.upper())\n",
        "                        .drop(columns=['riesgos'])\n",
        "                          )\n",
        "\n",
        "  # edas, gabo, torre de control\n",
        "  edas = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcEdas'])\n",
        "  bauto = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcConsolidadoBautoLastStatus'])\n",
        "  torreRaw = read_from_google_sheets(gc,id_torre_de_control,sheetname='Asignación compradores')\n",
        "  torreRaw.columns\n",
        "  clientes = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcClientes'])\n",
        "  # clientes\n",
        "  subset_columns = ['id_lead','origen_automarket','id_comprador','id_de_ultimo_pedido','folio_bauto',\n",
        "                    'espacio_automarket','asesor_de_ventas','fecha_de_asignacion','total_apartados',\n",
        "                    'estatus_de_lead','lead_contactado_(visualiza_cc)',\n",
        "                    'fecha_de_cierre_del_lead','motivos_de_cancelacion',\n",
        "                    'correo_recibido_en_buzon_contingencia','documentacion_completa_contingencia',\n",
        "                    ]\n",
        "  rename_dict = {'lead_contactado_(visualiza_cc)':'lead_contactado'}\n",
        "\n",
        "  torre = (torreRaw\n",
        "  .pipe(process_columns)\n",
        "  [subset_columns]\n",
        "  .assign(folio = lambda x: pd.to_numeric(x['folio_bauto'],errors='coerce').astype('Int64'),\n",
        "          id_comprador = lambda x: pd.to_numeric(x['id_comprador'],errors='coerce').astype('Int64'),\n",
        "          fecha_de_asignacion = lambda x: pd.to_datetime(x['fecha_de_asignacion'],format='%d/%m/%Y').dt.strftime('%Y-%m-%d'),\n",
        "          #  fecha_de_cierre_del_lead = lambda x: pd.to_datetime(x['fecha_de_cierre_del_lead'],format='%d/%m/%Y').dt.strftime('%Y-%m-%d'),\n",
        "          )\n",
        "  .rename(columns=rename_dict)\n",
        "  .sort_values(by='fecha_de_asignacion',ascending=False)\n",
        "  )\n",
        "\n",
        "  folder_id_folios_rod = '1OW4yxE7h8BCcn0mqhCfk05B4_27Ghvfd'\n",
        "  files_rod = list_file_ids_for_drive_folder(drive,folder_id_folios_rod)\n",
        "  files = list(files_rod.keys())\n",
        "  files = [x for x in files if '.xlsx' in x]\n",
        "  latest_rod_id = files_rod.get(files[0]) ## cambiar este siempre\n",
        "  print('Fecha archivo folios rod:')\n",
        "  print(files[0])\n",
        "  latest_rod_id\n",
        "  from_drive_to_local(drive,latest_rod_id,'rod_latest.xlsx')\n",
        "  rod = (pd.read_excel('rod_latest.xlsx')\n",
        "        .rename(columns={'Name':'intento',\n",
        "                        'MX_ATN_Id_Simulacion__c':'n_simulacion',\n",
        "                        'MX_ATN_creditId__c':'folio',\n",
        "                        'MX_ATN_Account__r.Name':'name',\n",
        "                        'MX_ATN_Account__r.MX_ATN_CommerceId__c':'id_am',\n",
        "                        'MX_ATN_Account__r.MX_ATN_PrimaryContact__r.Email':'email',\n",
        "                        'MX_ATN_Account__r.MX_ATN_PrimaryContact__r.MobilePhone':'phone',\n",
        "                        'MX_ATN_Status__c':'status'})\n",
        "        .assign(CreatedDate = lambda x: pd.to_datetime(x.CreatedDate, format=\"%d/%m/%Y, %H:%M\"),\n",
        "                phone = lambda x: x.phone.astype('Int64').astype(str))\n",
        "        )\n",
        "  flag_insumos_api=1\n",
        "except Exception as e:\n",
        "  print('Error en load de insumos para funnel api. No se incluirá en la master table.')\n",
        "  print(e)\n",
        "  flag_insumos_api=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datedf = get_dates_dataframe(start='2024-03-01').assign(date = lambda x: x.date.dt.strftime('%Y-%m-%d'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clientes  \n",
        "clientes_by_date = (clientes\n",
        " .rename(columns={'customer_since':'date'})\n",
        " .groupby('date')['id_am'].nunique()\n",
        " .to_frame()\n",
        " .rename(columns={'id_am':'usuarios_registrados'})\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visitas unicas\n",
        "visitas_date = (visitas_unicas\n",
        " .groupby(['date']).sum()\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# funnel vendedor\n",
        "sum_cols_vendedor = adobe_vendedor_total.filter(like='fv_').columns\n",
        "rename_dict_vendedor = {'fv_app_click_start':'fv_0_app_click_start',\n",
        "                        'fv_app_page_visit':'fv_1_marca_modelo',\n",
        "                        'fv_app_step_2':'fv_2_version',\n",
        "                        'fv_app_step_3':'fv_3_tenemos_tu_version',\n",
        "                        'fv_app_step_4':'fv_4_precio',\n",
        "                        'fv_app_step_6':'fv_5_datos_complementarios',\n",
        "                        'fv_app_step_8':'fv_6_espacio_automarket',\n",
        "                        'fv_app_step_9':'fv_7_fotografias',\n",
        "                        'fv_app_step_10':'fv_8_exito_publicacion'\n",
        "                        }\n",
        "funnel_vendedor_date = (adobe_vendedor_total\n",
        "    .groupby(['date'])[sum_cols_vendedor].sum()\n",
        "    .rename(columns=rename_dict_vendedor)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# funnel comprador\n",
        "sum_cols_comprador = adobe_comprador_total.filter(like='fc_').columns\n",
        "rename_dict_comprador = {'fc_app_click_start':'fc_0_app_click_start',\n",
        "                        'fc_app_page_visit':'fc_1_onboarding',\n",
        "                        'fc_app_completed':'fc_2_apartado_exitoso',\n",
        "                        }\n",
        "funnel_comprador_date = (adobe_comprador_total\n",
        "    .groupby(['date'])[sum_cols_comprador].sum()\n",
        "    .rename(columns=rename_dict_comprador)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cancelaciones\n",
        "cancelaciones_date = (cancelaciones\n",
        " .rename(columns={'cancelled_at':'date'})\n",
        " .groupby(['date'])['sku'].nunique()\n",
        " .rename('publicaciones_canceladas')\n",
        " .to_frame()\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# publicaciones\n",
        "publicaciones_date = (publicaciones\n",
        " [lambda x: x.published_at.notna()]\n",
        "  .rename(columns={'published_at':'date'})\n",
        " .groupby(['date'])['sku'].nunique()\n",
        " .rename('publicaciones')\n",
        " .to_frame() \n",
        " )\n",
        "showroom_map = {'Reforma 510':'torre',\n",
        "                'Metrópoli Patriotismo':'patriotismo',\n",
        "                'Samara Satélite':'samara'}\n",
        "publicaciones_espacio_date = (publicaciones\n",
        " [lambda x: x.published_at.notna()]\n",
        " .assign(year_month=lambda x:pd.to_datetime( x['published_at']).dt.strftime('%Y-%m'),\n",
        "         showroom = lambda x:x.showroom.map(showroom_map))\n",
        "  .rename(columns={'published_at':'date'})\n",
        " .groupby(['date','showroom'])['sku'].nunique()\n",
        " .unstack('showroom')\n",
        " .fillna(0)\n",
        " )\n",
        "publicaciones_espacio_date.columns = [f'publicaciones_{showroom}' for showroom in publicaciones_espacio_date.columns]\n",
        "publicaciones_activas_date = (publicaciones\n",
        " [lambda x: x.flag_publicacion_activa==1]\n",
        ".rename(columns={'published_at':'date'})\n",
        " .groupby(['date'])['sku'].nunique()\n",
        " .rename('publicaciones_activas')\n",
        " .to_frame()\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pedidos\n",
        "pedidos_date = (pedidos\n",
        " .rename(columns={'fecha_de_creacion':'date'})\n",
        " .groupby(['date','multiapartado'])\n",
        " ['sf_order_id'].nunique()\n",
        " .unstack('multiapartado')\n",
        " .rename(columns={0:'apartados_unicos',\n",
        "               1:'multiapartados'})\n",
        " .fillna(0)\n",
        " .assign(apartados = lambda x: x.sum(axis=1))\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ventas\n",
        "ventas_pago_date = (ventas\n",
        " .rename(columns={'fecha_de_entrega':'date'})\n",
        " .groupby(['date','tipo_de_venta'])\n",
        " .size()\n",
        " .rename({0:'ventas'})\n",
        " .unstack('tipo_de_venta')\n",
        " .fillna(0)\n",
        " )\n",
        "ventas_pago_date.columns = [f'ventas_{tipo}' for tipo in ventas_pago_date.columns]\n",
        "ventas_pago_date = ventas_pago_date.assign(ventas = lambda x: x.sum(axis=1))\n",
        "ventas_espacio_date = (ventas\n",
        " .rename(columns={'fecha_de_entrega':'date'})\n",
        " .groupby(['date','espacio_am'])\n",
        " .size()\n",
        " .rename({0:'ventas'})\n",
        " .unstack('espacio_am')\n",
        " .fillna(0)\n",
        " )\n",
        "ventas_espacio_date.columns = [f'ventas_{showroom}' for showroom in ventas_espacio_date.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# business case \n",
        "bc_diario = (business_case_df\n",
        "    .assign(days_in_month = lambda x: pd.to_datetime(x.mes).dt.days_in_month,\n",
        "            year_month = lambda x: pd.to_datetime(x.mes).dt.strftime('%Y-%m'))\n",
        "    \n",
        "    )\n",
        "bc_diario = (bc_diario\n",
        "    .assign(**{c:bc_diario[c]/bc_diario['days_in_month'] for c in bc_diario.columns \n",
        "               if c not in ['mes','days_in_month','year_month']})\n",
        "    .drop(columns=['mes','days_in_month'])\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### process apis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if flag_insumos_api==1:\n",
        "        bauto_mod_api = (bauto\n",
        "                .assign(flag_eda = lambda x: np.where(x.folio.isin(edas.folio.unique()),1,0),\n",
        "                        flag_tc = lambda x: np.where(x.folio.isin(torre.folio.unique()),1,0),\n",
        "                        origen_real= lambda x: np.where(x.folio.isin(edas.folio.unique()),'EDA',x.origen),\n",
        "                        decisionsistema = lambda x: x.decisionsistema.apply(remove_accents).str.strip().str.upper(),\n",
        "                        tareaactual = lambda x: x.tareaactual.apply(remove_accents).str.strip().str.upper(),\n",
        "                        telefono = lambda x: x.telefono.astype('Int64')\n",
        "                        )\n",
        "                [lambda x: x.origen_real=='API']\n",
        "                .merge(cat_tarea_actual,on='tareaactual',how='left')\n",
        "                .merge(cat_decision_sistema,on='decisionsistema',how='left')\n",
        "                .drop_duplicates()\n",
        "                .sort_values(by='fecha_creacion',ascending=False)\n",
        "                )\n",
        "\n",
        "\n",
        "        dummies_status_df = pd.get_dummies(bauto_mod_api.status_automarket)*1\n",
        "        dummies_status_df.columns = [f'status_automarket_{x}' for x in dummies_status_df.columns]\n",
        "        bauto_mod_api = pd.concat([bauto_mod_api,dummies_status_df],axis=1)\n",
        "\n",
        "\n",
        "        bauto_by_date=(bauto_mod_api\n",
        "        .groupby('fecha_creacion',as_index=False)\n",
        "        .agg(bauto_folios_api=('folio','nunique'),\n",
        "        bauto_folios_en_proceso = ('status_automarket_PROCESO DESEMBOLSO','sum'),\n",
        "        bauto_folios_desembolso = ('status_automarket_DESEMBOLSADO','sum'),\n",
        "        bauto_folios_rechazado = ('status_automarket_RECHAZADO','sum'),\n",
        "        bauto_folios_inicio_solicitud = ('status_automarket_INICIO SOLICITUD','sum'),\n",
        "        bauto_folios_revision_riesgo = ('status_automarket_REVISION RIESGOS','sum'),\n",
        "        \n",
        "        )\n",
        "        .rename(columns={'fecha_creacion':'date'})\n",
        "\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if flag_insumos_api==1:\n",
        "     rod_by_date = (rod\n",
        "                    .assign(date = lambda x:pd.to_datetime(x.CreatedDate).dt.strftime('%Y-%m-%d'),\n",
        "                         id_am_con_folio = lambda x: np.where(x.folio.notna(),x.id_am,np.nan))\n",
        "                    .groupby('date',as_index=False)\n",
        "                    .agg(fapi_intentos_solicitud=('intento','nunique'),\n",
        "                         fapi_usuarios_con_intento=('id_am','nunique'),\n",
        "                         fapi_folios=('folio','nunique'),\n",
        "                         fapi_usuarios_con_folio=('id_am_con_folio','nunique'),\n",
        "                         )\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "master = (datedf\n",
        "          .merge(visitas_date,on='date',how='left')\n",
        "          .merge(funnel_vendedor_date,on='date',how='left')\n",
        "          .merge(funnel_comprador_date,on='date',how='left')\n",
        "          .merge(publicaciones_date,on='date',how='left')\n",
        "          .merge(publicaciones_activas_date,on='date',how='left')\n",
        "          .merge(publicaciones_espacio_date,on='date',how='left')\n",
        "          .merge(cancelaciones_date,on='date',how='left')\n",
        "          .merge(pedidos_date,on='date',how='left')\n",
        "          .merge(ventas_espacio_date,on='date',how='left')\n",
        "          .merge(ventas_pago_date,on='date',how='left')\n",
        "          .merge(clientes_by_date,on='date',how='left')\n",
        "          .fillna(0)\n",
        "          .assign(year = lambda x:pd.to_datetime(x.date).dt.year,\n",
        "                  month = lambda x:pd.to_datetime(x.date).dt.month,\n",
        "                  year_month=lambda x:pd.to_datetime( x['date']).dt.strftime('%Y-%m'),\n",
        "                  year_week = lambda x:pd.to_datetime( x['date']).dt.strftime('%Y-%U'),\n",
        "                  day_of_week = lambda x:pd.to_datetime( x['date']).dt.strftime('%A'),\n",
        "                  monday_of_week=lambda x: (pd.to_datetime(x.date) - \n",
        "                                            pd.to_timedelta(pd.to_datetime(x.date).dt.dayofweek, unit=\"d\")).dt.strftime(\"%Y-%m-%d\"),\n",
        "                  )\n",
        "          .merge(bc_diario,on='year_month',how='left')\n",
        "          \n",
        "          )\n",
        "if flag_insumos_api==1:\n",
        "        print('Se incluirá funnel api en master table...')\n",
        "        master = (master\n",
        "                .merge(rod_by_date,on='date',how='left')\n",
        "                .merge(bauto_by_date,on='date',how='left')\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## write"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_master_table_id = '1v8EAje4iFtzSHVoNjQusmjGSjhhnvzaH6vVDlYh0b4U'\n",
        "update_sheets_in_drive_folder(gc,output_master_table_id,'Hoja 1',master)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## free memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_del = ['ventas','ventas_espacio_date','ventas_pago_date','business_case_df',\n",
        "               'publicaciones','publicaciones_activas_date','publicaciones_date','publicaciones_espacio_date',\n",
        "               'pedidos','pedidos_date',\n",
        "               'cancelaciones_date','cancelaciones',\n",
        "               'funnel_comprador_date','funnel_vendedor_date',\n",
        "               'visitas_date',\n",
        "               'clientes',\n",
        "               'adobe_comprador_total','adobe_vendedor_total','bc_diario',\n",
        "               'rod_by_date',\"bauto\",\"bauto_by_date\",\"bauto_mod_api\",\n",
        "               \"rod\",\"edas\",\"torreRaw\",\"torre\",\"dummies_status_df\",\n",
        "               \"cat_tarea_actual\",\"cat_decision_sistema\"]\n",
        "for v in vars_to_del:\n",
        "    try:\n",
        "        del globals()[v]\n",
        "    except Exception as e:\n",
        "        print(f\"could not delete var {v}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc as gcol\n",
        "gcol.collect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
