{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f99fac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from_drive = True  # same flag you use everywhere\n",
    "\n",
    "if os.environ.get(\"ATLAS_BOOTSTRAPPED\") != \"1\":\n",
    "    # ---------- GIT ON COLAB ONLY ----------\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        git_token = userdata.get('gitToken')\n",
    "        git_user = userdata.get('gitUser')\n",
    "        git_url = f'https://{git_token}@github.com/rene-aum/Atlas.git'\n",
    "        branch_to_pull = 'dev'\n",
    "\n",
    "        os.chdir('/content')\n",
    "\n",
    "        if not os.path.isdir('Atlas'):\n",
    "            !git clone {git_url}\n",
    "\n",
    "        %cd Atlas\n",
    "        !git fetch origin {branch_to_pull}\n",
    "        !git checkout {branch_to_pull}\n",
    "        !git pull origin {branch_to_pull}\n",
    "\n",
    "        !pip install -r PipelinesConsumo/src/requirements.txt\n",
    "        %cd PipelinesConsumo\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Running in other environment not colab probably!')\n",
    "\n",
    "    # ---------- DRIVE + SHEETS ----------\n",
    "    if from_drive:\n",
    "        from pydrive2.auth import GoogleAuth\n",
    "        from pydrive2.drive import GoogleDrive\n",
    "        from google.colab import auth\n",
    "        from oauth2client.client import GoogleCredentials\n",
    "        import gspread\n",
    "        from google.auth import default\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        import gdown\n",
    "\n",
    "        auth.authenticate_user()\n",
    "        gauth = GoogleAuth()\n",
    "        gauth.credentials = GoogleCredentials.get_application_default()\n",
    "        drive = GoogleDrive(gauth)\n",
    "\n",
    "        creds, _ = default()\n",
    "        gc = gspread.authorize(creds)\n",
    "\n",
    "    os.environ[\"ATLAS_BOOTSTRAPPED\"] = \"1\"\n",
    "else:\n",
    "    print(\"Bootstrap already done, assuming orchestrator ran it.\")\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "from utils.utils import (get_dates_dataframe,\n",
    "                       add_year_week,\n",
    "                       custom_read,\n",
    "                       process_columns,\n",
    "                       remove_accents)\n",
    "from PipelinesConsumo.src.rawAtlas import RawAtlas\n",
    "from PipelinesConsumo.src.processedAtlas import ProcessedAtlas\n",
    "from src.transformed import Transformed\n",
    "from utils.drive_toolbox import(from_drive_to_local,\n",
    "                             get_last_modification_date_drive,\n",
    "                             create_sheets_in_drive_folder,\n",
    "                             update_sheets_in_drive_folder,\n",
    "                             read_from_google_sheets,\n",
    "                             list_file_ids_for_drive_folder,\n",
    "                             create_csv_file_in_drive_folder,\n",
    "                             write_csv_to_drive,\n",
    "                             read_csv_from_drive)\n",
    "from src.constants import (atlas_raw_output_folder_id,\n",
    "                           atlas_consumo_output_folder_id,\n",
    "                           consumo_sheets_ids_dict,\n",
    "                           data_source_folder_id,\n",
    "                           raw_output_ids,\n",
    "                           folder_id_bauto_gabo,\n",
    "                           id_reporte_ventas,\n",
    "                           id_edas_referenciados,\n",
    "                           id_torre_de_control\n",
    "                           )\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafccf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.auth import default\n",
    "\n",
    "# 1. Configurar credenciales\n",
    "creds, _ = default()\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# 2. Definir el ID del nuevo archivo\n",
    "file_id = '1raTDAr2fRnP-B9VJi58gNgD6KQVkBMvH'\n",
    "\n",
    "# 3. Descargar el flujo de datos\n",
    "request = drive_service.files().get_media(fileId=file_id)\n",
    "downloaded = io.BytesIO()\n",
    "downloader = MediaIoBaseDownload(downloaded, request)\n",
    "\n",
    "done = False\n",
    "while done is False:\n",
    "    status, done = downloader.next_chunk()\n",
    "    if status:\n",
    "        print(f\"Descarga: {int(status.progress() * 100)}%\")\n",
    "\n",
    "# 4. Cargar en DataFrame\n",
    "downloaded.seek(0)\n",
    "df = pd.read_csv(downloaded, low_memory=False)\n",
    "\n",
    "print(\"\\n--- Carga Exitosa ---\")\n",
    "print(f\"Filas: {df.shape[0]} | Columnas: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591478a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_csv_final(drive_instance, file_id):\n",
    "    # 1. Descarga el archivo\n",
    "    file_drive = drive_instance.CreateFile({'id': file_id})\n",
    "    temp_filename = 'data_reporte.csv'\n",
    "    file_drive.GetContentFile(temp_filename)\n",
    "\n",
    "    # 2. Leemos saltando las 8 filas y con el encoding correcto\n",
    "    # No usamos usecols aqu√≠ para evitar el error de \"out of bounds\"\n",
    "    df = pd.read_csv(temp_filename, encoding='latin-1', skiprows=8, low_memory=False)\n",
    "\n",
    "    # 3. Eliminamos la primera columna (Columna A)\n",
    "    # iloc[:, 1:] significa: \"todas las filas, desde la columna 1 hasta el final\"\n",
    "    df = df.iloc[:, 1:]\n",
    "\n",
    "    # Limpieza extra: eliminar columnas que est√©n completamente vac√≠as (opcional)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Ejecuci√≥n\n",
    "id_csv = '1gkgwmIJ4uctdxu_pdUU9LCyj4NHhRR_7'\n",
    "df_1 = read_csv_final(drive, id_csv)\n",
    "\n",
    "print(f\"Columnas actuales: {len(df_1.columns)}\")\n",
    "df_1.head(2)\n",
    "\n",
    "\n",
    "#print(df_1.columns.tolist())\n",
    "\n",
    "parent_folder_pedidos = list(list_file_ids_for_drive_folder(drive,'1yVMEVT9zooZXOsiYHnZ1FZVGDZJQQ-sv').items())[0]\n",
    "print(parent_folder_pedidos)\n",
    "file_pedidos_reciente = list(list_file_ids_for_drive_folder(drive,parent_folder_pedidos[1]).items())[0]\n",
    "print(file_pedidos_reciente)\n",
    "id_pedidos_reciente = file_pedidos_reciente[1]\n",
    "print(id_pedidos_reciente)\n",
    "\n",
    "from_drive_to_local(drive,id_pedidos_reciente,'pedidos_latest.csv')\n",
    "pedidos = pd.read_csv('pedidos_latest.csv',encoding='latin-1',skiprows=8)\n",
    "unamed_cols = [col for col in pedidos.columns if 'Unnamed' in col]\n",
    "pedidos = pedidos.drop(columns=unamed_cols)\n",
    "df_1=pedidos.copy()\n",
    "\n",
    "fecha_max = pd.to_datetime(df_1['Fecha de creaci√≥n'], format='%d/%m/%Y').max()\n",
    "fecha_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfd0bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Asegurar que la fecha sea v√°lida y calcular los d√≠as\n",
    "df_1['Fecha de creaci√≥n'] = pd.to_datetime(df_1['Fecha de creaci√≥n'],format='%d/%m/%Y', errors='coerce')\n",
    "hoy = datetime.now()\n",
    "df_1['dias_abiertos'] = (hoy - df_1['Fecha de creaci√≥n']).dt.days\n",
    "\n",
    "# 2. Definir los cortes de 30 en 30 d√≠as y sus etiquetas\n",
    "# Creamos rangos hasta 360 d√≠as y un grupo final para m√°s de un a√±o\n",
    "bins = [0, 30, 60, 90, 120, 150, 180, 360, 10000]\n",
    "labels = [\n",
    "    '0-30 d√≠as',\n",
    "    '31-60 d√≠as',\n",
    "    '61-90 d√≠as',\n",
    "    '91-120 d√≠as',\n",
    "    '121-150 d√≠as',\n",
    "    '151-180 d√≠as',\n",
    "    '181-360 d√≠as',\n",
    "    'M√°s de 360 d√≠as'\n",
    "]\n",
    "\n",
    "# Creamos la columna de rangos\n",
    "df_1['Rango_Aging'] = pd.cut(df_1['dias_abiertos'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# 3. Etapas a validar\n",
    "etapas_interes = [\n",
    "    'Revisi√≥n de auto',\n",
    "    'Acuerdo de compraventa',\n",
    "    'Negociaci√≥n de precio',\n",
    "    'Cita para Entrega',\n",
    "    'Auto en cita'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df733c70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ***Generaci√≥n del reporte***\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce811573",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIGURACI√ìN DE B√öSQUEDA ---\n",
    "dias_minimo = 0\n",
    "dias_maximo = 1500\n",
    "estado_buscado = ['Revisi√≥n de auto', 'Acuerdo de compraventa', 'Negociaci√≥n de precio', 'Cita para Entrega', 'Auto en cita']\n",
    "id_sheets_1 = '1qitnBwGCg7n-IFPaOBZfdBK2vCplNTqPOjpiJcoZX7k' # Torre Vieja\n",
    "id_sheets_2 = '1k8rguLeF1O33XCaVDxPiQ1C4SbxLDSIeqNcriYtsF-k' # Torre Nueva\n",
    "# ---------------------------------\n",
    "\n",
    "def get_df_from_ws(ws):\n",
    "    data = ws.get_all_values()\n",
    "    if not data: return pd.DataFrame()\n",
    "    headers = data[0]\n",
    "    return pd.DataFrame(data[1:], columns=headers)\n",
    "\n",
    "# 1. CARGA DE DATOS CRM\n",
    "sh1 = gc.open_by_key(id_sheets_1)\n",
    "df_cc1 = get_df_from_ws(sh1.worksheet('Contact Center'))\n",
    "df_asig1 = get_df_from_ws(sh1.worksheet('Asignaci√≥n compradores'))\n",
    "\n",
    "sh2 = gc.open_by_key(id_sheets_2)\n",
    "df_cc2 = get_df_from_ws(sh2.worksheet('contact center'))\n",
    "df_asig2 = get_df_from_ws(sh2.worksheet('asignacion'))\n",
    "\n",
    "# 2. PROCESAMIENTO BASE PRINCIPAL (df_1)\n",
    "df_1['Fecha de creaci√≥n'] = pd.to_datetime(df_1['Fecha de creaci√≥n'], errors='coerce')\n",
    "hoy = datetime.now()\n",
    "df_1['dias_abiertos'] = (hoy - df_1['Fecha de creaci√≥n']).dt.days.fillna(0).astype(int)\n",
    "df_1['N√∫mero de pedido_num'] = pd.to_numeric(df_1['N√∫mero de pedido'], errors='coerce').fillna(0).astype(int)\n",
    "df_1['Comprador: Id Comercio Externo'] = pd.to_numeric(df_1['Comprador: Id Comercio Externo'], errors='coerce').astype('Int64')\n",
    "\n",
    "filtro = (\n",
    "    (df_1['Estado'].isin(estado_buscado)) &\n",
    "    (df_1['dias_abiertos'] > dias_minimo) &\n",
    "    (df_1['dias_abiertos'] <= dias_maximo)\n",
    ")\n",
    "df_resultados = df_1[filtro].copy()\n",
    "\n",
    "# 3. L√ìGICA DE B√öSQUEDA DE LEADS\n",
    "def obtener_lista_leads(row):\n",
    "    num_pedido = row['N√∫mero de pedido_num']\n",
    "    id_comercio = str(row['Comprador: Id Comercio Externo']).strip().split('.')[0]\n",
    "    leads_encontrados = []\n",
    "\n",
    "    m1_ped = df_cc1[pd.to_numeric(df_cc1['ID de pedido'], errors='coerce') == num_pedido]\n",
    "    if not m1_ped.empty: leads_encontrados.extend(m1_ped['ID Lead'].unique().tolist())\n",
    "\n",
    "    if not leads_encontrados and id_comercio not in ['<NA>', 'nan', 'N/A']:\n",
    "        m1_com = df_asig1[df_asig1['ID comprador'].astype(str) == id_comercio]\n",
    "        if not m1_com.empty: leads_encontrados.extend(m1_com['ID Lead'].unique().tolist())\n",
    "\n",
    "    m2_ped = df_cc2[pd.to_numeric(df_cc2['ID de pedido'], errors='coerce') == num_pedido]\n",
    "    if not m2_ped.empty:\n",
    "        for l in m2_ped['ID Lead'].unique():\n",
    "            if l not in leads_encontrados: leads_encontrados.append(l)\n",
    "\n",
    "    if not leads_encontrados and id_comercio not in ['<NA>', 'nan', 'N/A']:\n",
    "        m2_com = df_asig2[df_asig2['id comprador'].astype(str) == id_comercio]\n",
    "        if not m2_com.empty:\n",
    "            col_lead = 'id lead' if 'id lead' in df_asig2.columns else 'ID Lead'\n",
    "            for l in m2_com[col_lead].unique():\n",
    "                if l not in leads_encontrados: leads_encontrados.append(l)\n",
    "\n",
    "    return leads_encontrados if leads_encontrados else [\"N/A\"]\n",
    "\n",
    "df_resultados['ID Lead'] = df_resultados.apply(obtener_lista_leads, axis=1)\n",
    "df_expandido = df_resultados.explode('ID Lead').reset_index(drop=True)\n",
    "\n",
    "# 4. FUNCI√ìN PARA BUSCAR INFO EXTRA (CONSERVANDO SKU)\n",
    "def buscar_info_extra(row):\n",
    "    lead = str(row['ID Lead']).strip().split('.')[0]\n",
    "    info = {\n",
    "        'Estatus de Lead': 'N/A', 'Origen': 'N/A', 'Asesor Ventas': 'N/A',\n",
    "        'Asesor CC': 'N/A', 'ID Comprador': 'N/A', 'Fecha Asignaci√≥n': 'N/A',\n",
    "        'Torre de Control': 'N/A', 'SKU PROD': 'N/A', 'asesor credito': 'N/A'\n",
    "    }\n",
    "\n",
    "    if lead == \"N/A\": return pd.Series(info)\n",
    "\n",
    "    # B√∫squeda Torre 1\n",
    "    m1 = df_asig1[df_asig1['ID Lead'].astype(str).str.contains(lead, na=False)]\n",
    "    if not m1.empty:\n",
    "        res = m1.iloc[0]\n",
    "        info.update({\n",
    "            'Estatus de Lead': res.get('Estatus de Lead', 'N/A'),\n",
    "            'SKU PROD': res.get('SKU de Producto', 'N/A'),\n",
    "            'Origen': res.get('Origen AutoMarket', 'N/A'),\n",
    "            'Asesor Ventas': res.get('Asesor de Ventas', 'N/A'),\n",
    "            'Asesor CC': res.get('Asesor CC front', 'N/A'),\n",
    "            'ID Comprador': res.get('ID comprador', 'N/A'),\n",
    "            'Fecha Asignaci√≥n': res.get('Fecha de asignaci√≥n', 'N/A'),\n",
    "            'Torre de Control': 'TC V1'\n",
    "        })\n",
    "        return pd.Series(info)\n",
    "\n",
    "    # B√∫squeda Torre 2\n",
    "    m2 = df_asig2[df_asig2['id lead'].astype(str).str.contains(lead, na=False)] if 'id lead' in df_asig2.columns else pd.DataFrame()\n",
    "    if not m2.empty:\n",
    "        res = m2.iloc[0]\n",
    "        info.update({\n",
    "            'Estatus de Lead': res.get('estatus de lead', 'N/A'),\n",
    "            'SKU PROD': res.get('sku de producto', 'N/A'),\n",
    "            'asesor credito': res.get('asesor credito', 'N/A'),\n",
    "            'Origen': res.get('origen automarket', 'N/A'),\n",
    "            'Asesor Ventas': res.get('asesor espacio', 'N/A'),\n",
    "            'Asesor CC': res.get('asesor cc', 'N/A'),\n",
    "            'ID Comprador': res.get('id comprador', 'N/A'),\n",
    "            'Fecha Asignaci√≥n': res.get('fecha de asignacion', 'N/A'),\n",
    "            'Torre de Control': 'TC V2'\n",
    "        })\n",
    "        return pd.Series(info)\n",
    "\n",
    "    return pd.Series(info)\n",
    "\n",
    "df_info = df_expandido.apply(buscar_info_extra, axis=1)\n",
    "df_final = pd.concat([df_expandido, df_info], axis=1)\n",
    "\n",
    "# 5. C√ÅLCULO DE D√çAS\n",
    "df_final['d√≠as creaci√≥n-asignaci√≥n'] = df_final.apply(\n",
    "    lambda r: int(abs((pd.to_datetime(r['Fecha Asignaci√≥n'], errors='coerce') - r['Fecha de creaci√≥n']).days))\n",
    "    if pd.notna(r['Fecha de creaci√≥n']) and pd.notna(pd.to_datetime(r['Fecha Asignaci√≥n'], errors='coerce')) else \"N/A\", axis=1\n",
    ")\n",
    "\n",
    "# 6. TABLA FINAL: AQU√ç CONSERVAMOS TODO\n",
    "# En lugar de filtrar columnas, usamos todas las existentes en df_final\n",
    "df_tabla = df_final.copy()\n",
    "\n",
    "# Renombrar solo si la columna existe para evitar KeyErrors\n",
    "if 'Activo: Producto: Nombre del producto' in df_tabla.columns:\n",
    "    df_tabla = df_tabla.rename(columns={'Activo: Producto: Nombre del producto': 'Descripci√≥n Auto'})\n",
    "\n",
    "# Formateo de fechas\n",
    "df_tabla['Fecha de creaci√≥n'] = df_tabla['Fecha de creaci√≥n'].dt.strftime('%Y-%m-%d')\n",
    "df_tabla = df_tabla.sort_values(by='dias_abiertos', ascending=False)\n",
    "\n",
    "print(f\"üìä REPORTE COMPLETO (TODAS LAS COLUMNAS)\")\n",
    "display(df_tabla.reset_index(drop=True))\n",
    "\n",
    "df_tabla = df_tabla.sort_values(by=['N√∫mero de pedido','d√≠as creaci√≥n-asignaci√≥n'],ascending=[True,True])\n",
    "\n",
    "# Desduplicar por n√∫mero de pedido\n",
    "# el df ya est√° ordenado\n",
    "df_tabla = df_tabla.groupby('N√∫mero de pedido').head(1)\n",
    "\n",
    "df_tabla['N√∫mero de pedido'].nunique(),df_tabla.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1537c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIGURACI√ìN DE EXPORTACI√ìN ---\n",
    "# Nueva carpeta de destino proporcionada\n",
    "id_carpeta_destino = '1q3OtSK_RrZKLYb0YXtIMlDxmbRJPt-YY'\n",
    "id_latest = '1Shb0TjoBLN4iDJBp9--BFs4V1s6MxaRO0sdmoRl0Z2I'\n",
    "\n",
    "# Generamos el nombre con el formato exacto: Estatus Salesforce ddmmaaaa-hh:mm:ss\n",
    "nombre_archivo = datetime.now().strftime('Estatus Salesforce %d%m%Y-%H:%M:%S')\n",
    "# ------------------------------------\n",
    "\n",
    "try:\n",
    "    # 1. Crear el nuevo archivo de Google Sheets directamente en la carpeta de destino\n",
    "    nuevo_sh = gc.create(nombre_archivo, id_carpeta_destino)\n",
    "\n",
    "    # 2. Renombrar la primera hoja a 'Pedidos'\n",
    "    hoja_pedidos = nuevo_sh.get_worksheet(0)\n",
    "    hoja_pedidos.update_title('Pedidos')\n",
    "\n",
    "    # 3. Preparar los datos para la exportaci√≥n (Mantenimiento de UTF-8)\n",
    "    df_export = df_tabla.copy()\n",
    "\n",
    "    # Convertimos el DataFrame a una lista de listas\n",
    "    datos_a_enviar = [df_export.columns.values.tolist()] + df_export.values.tolist()\n",
    "\n",
    "    # 4. Volcar la informaci√≥n en la hoja\n",
    "    hoja_pedidos.update('A1', datos_a_enviar)\n",
    "\n",
    "    # 5. Confirmaci√≥n y enlace\n",
    "    print(f\"‚úÖ Reporte exportado con √©xito (UTF-8 preservado).\")\n",
    "    print(f\"üìÑ Archivo: {nombre_archivo}\")\n",
    "    print(f\"üîó Enlace: {nuevo_sh.url}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la exportaci√≥n a Google Sheets: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68164560",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cargar el dataframe (asumiendo que la funci√≥n ya est√° definida)\n",
    "vsraw = read_csv_from_drive(drive, '1LnxD5KjR3iEbN2nmomUZwMp3kLYzES06')\n",
    "\n",
    "# Cambiar nombres de columnas\n",
    "nuevos_nombres_raw = {\n",
    "    'order_id':                  'ID Commerce',\n",
    "    'sku':                       'SKU',\n",
    "    'status_product':            'Estatus de Publicaci√≥n'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c945ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vsraw = vsraw.rename(columns=nuevos_nombres_raw)\n",
    "\n",
    "# Definimos el mapeo: 'Nombre Actual': 'Nombre Nuevo'\n",
    "nombres_nuevos_DF = {\n",
    "    'N√∫mero de pedido':           'N√∫mero de Pedido',\n",
    "    'Pedido: Id comercio externo':'ID Commerce',\n",
    "    'Estado':                     'Estado en TC',\n",
    "    'dias_abiertos':              'Cantidad de d√≠as abierto',\n",
    "    'Fecha de creaci√≥n':          'Fecha de creaci√≥n de pedido',\n",
    "    'ID Lead':                    'ID Lead',\n",
    "    'Estatus de Lead':            'Estatus de Lead en TC',\n",
    "    'Origen':                     'Origen de Lead',\n",
    "    'Asesor Ventas':              'Asesor de Venta (EAM)',\n",
    "    'asesor credito':             'Asesor de Cr√©dito (C√©lula de Cr√©dito)',\n",
    "    'Asesor CC':                  'Asesor CC (Contact Center)',\n",
    "    'ID Comprador':               'ID Comprador',\n",
    "    'Fecha Asignaci√≥n':           'Fecha de Asignaci√≥n',\n",
    "    'd√≠as creaci√≥n-asignaci√≥n':   'D√≠as de diferencia entre Creaci√≥n y Asignaci√≥n',\n",
    "    'Torre de Control':           'TC donde est√° el Leal',\n",
    "    'Descripci√≥n Auto':           'Auto'\n",
    "}\n",
    "\n",
    "# Aplicamos el cambio en una sola l√≠nea\n",
    "df_export = df_export.rename(columns=nombres_nuevos_DF)\n",
    "# Merge (Left Join)\n",
    "# Tomamos como principal df_export (left) y lo unimos con vsraw por 'ID Commerce'\n",
    "df_final = df_export.merge(\n",
    "    vsraw[['ID Commerce', 'SKU', 'Estatus de Publicaci√≥n']],\n",
    "    on='ID Commerce',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_final = df_final[df_final['Estatus de Publicaci√≥n'] == 'reserved']\n",
    "\n",
    "col_finales = [\n",
    "    'N√∫mero de Pedido', \n",
    "    'ID Commerce', \n",
    "    'Estado en TC', \n",
    "    'Cantidad de d√≠as abierto', \n",
    "    'Fecha de creaci√≥n de pedido', \n",
    "    'ID Lead', \n",
    "    'Estatus de Lead en TC', \n",
    "    'Origen de Lead', \n",
    "    'Asesor de Venta (EAM)', \n",
    "    'Asesor de Cr√©dito (C√©lula de Cr√©dito)', \n",
    "    'Asesor CC (Contact Center)', \n",
    "    'ID Comprador', \n",
    "    'Fecha de Asignaci√≥n', \n",
    "    'D√≠as de diferencia entre Creaci√≥n y Asignaci√≥n', \n",
    "    'TC donde est√° el Leal', \n",
    "    'Auto', \n",
    "    'SKU', \n",
    "    'Estatus de Publicaci√≥n'\n",
    "]\n",
    "\n",
    "# Creamos la tabla solo con lo que pediste\n",
    "df_final = df_final[col_finales].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d432bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_final.columns\n",
    "\n",
    "update_sheets_in_drive_folder(gc, '1Shb0TjoBLN4iDJBp9--BFs4V1s6MxaRO0sdmoRl0Z2I', 'Pedidos', df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afb0b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def enviar_aviso_finalizado():\n",
    "    # Tu URL del Webhook\n",
    "    webhook_url = \"https://chat.googleapis.com/v1/spaces/AAQAcQfW5IA/messages?key=AIzaSyDdI0hCZtE6vySjMm-WEfRq3CPzqKqqsHI&token=6bcIc7ptX82oYSxRpchIt7AJjrAKCnxcwrmynJ_eQyU\"\n",
    "    #webhook_url = \"https://chat.googleapis.com/v1/spaces/AAQAcQfW5IA/messages?key=AIzaSyDdI0hCZtE6vySjMm-WEfRq3CPzqKqqsHI&token=MyN5aj4JOhcNyV7wqLF_OmVvpgXUzKJemQcZefenrCg\"\n",
    "\n",
    "    try:\n",
    "        # El mensaje simple que solicitaste\n",
    "        payload = {\n",
    "            \"text\": f\"*Reporte de Estatus de Pedidos ejecutado correctamente*, la fecha m√°s reciente es: {fecha_max}\"\n",
    "        }\n",
    "\n",
    "        # Realizar el env√≠o\n",
    "        response = requests.post(\n",
    "            webhook_url,\n",
    "            data=json.dumps(payload),\n",
    "            headers={'Content-Type': 'application/json; charset=UTF-8'}\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Notificaci√≥n enviada a Google Chat.\")\n",
    "        else:\n",
    "            print(f\"Error al enviar: {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la funci√≥n: {e}\")\n",
    "\n",
    "# --- EJECUCI√ìN ---\n",
    "enviar_aviso_finalizado()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
