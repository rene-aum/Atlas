{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0366b07a",
   "metadata": {},
   "source": [
    "# Reporte Solicitudes Ara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23261696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from_drive = True  # same flag you use everywhere\n",
    "\n",
    "if os.environ.get(\"ATLAS_BOOTSTRAPPED\") != \"1\":\n",
    "    # ---------- GIT ON COLAB ONLY ----------\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        git_token = userdata.get('gitToken')\n",
    "        git_user = userdata.get('gitUser')\n",
    "        git_url = f'https://{git_token}@github.com/rene-aum/Atlas.git'\n",
    "        branch_to_pull = 'dev'\n",
    "\n",
    "        os.chdir('/content')\n",
    "\n",
    "        if not os.path.isdir('Atlas'):\n",
    "            !git clone {git_url}\n",
    "\n",
    "        %cd Atlas\n",
    "        !git fetch origin {branch_to_pull}\n",
    "        !git checkout {branch_to_pull}\n",
    "        !git pull origin {branch_to_pull}\n",
    "\n",
    "        !pip install -r PipelinesConsumo/src/requirements.txt\n",
    "        %cd PipelinesConsumo\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Running in other environment not colab probably!')\n",
    "\n",
    "    # ---------- DRIVE + SHEETS ----------\n",
    "    if from_drive:\n",
    "        from pydrive2.auth import GoogleAuth\n",
    "        from pydrive2.drive import GoogleDrive\n",
    "        from google.colab import auth\n",
    "        from oauth2client.client import GoogleCredentials\n",
    "        import gspread\n",
    "        from google.auth import default\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        import gdown\n",
    "\n",
    "        auth.authenticate_user()\n",
    "        gauth = GoogleAuth()\n",
    "        gauth.credentials = GoogleCredentials.get_application_default()\n",
    "        drive = GoogleDrive(gauth)\n",
    "\n",
    "        creds, _ = default()\n",
    "        gc = gspread.authorize(creds)\n",
    "\n",
    "    os.environ[\"ATLAS_BOOTSTRAPPED\"] = \"1\"\n",
    "else:\n",
    "    print(\"Bootstrap already done, assuming orchestrator ran it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "from utils.utils import (get_dates_dataframe,\n",
    "                       add_year_week,\n",
    "                       custom_read,\n",
    "                       process_columns,\n",
    "                       remove_accents)\n",
    "from PipelinesConsumo.src.rawAtlas import RawAtlas\n",
    "from PipelinesConsumo.src.processedAtlas import ProcessedAtlas\n",
    "from src.transformed import Transformed\n",
    "from utils.drive_toolbox import(from_drive_to_local,\n",
    "                             get_last_modification_date_drive,\n",
    "                             create_sheets_in_drive_folder,\n",
    "                             update_sheets_in_drive_folder,\n",
    "                             read_from_google_sheets,\n",
    "                             list_file_ids_for_drive_folder,\n",
    "                             create_csv_file_in_drive_folder,\n",
    "                             write_csv_to_drive,\n",
    "                             read_csv_from_drive)\n",
    "from src.constants import (atlas_raw_output_folder_id,\n",
    "                           atlas_consumo_output_folder_id,\n",
    "                           consumo_sheets_ids_dict,\n",
    "                           data_source_folder_id,\n",
    "                           raw_output_ids,\n",
    "                           folder_id_bauto_gabo,\n",
    "                           id_reporte_ventas,\n",
    "                           id_edas_referenciados,\n",
    "                           id_torre_de_control\n",
    "                           )\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b1c5c",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id_catalogos = \"1TE24Yl4lQ6ZxHJSw_ZDzb6W4XpB-21FL\"\n",
    "id_catalogos_status = list_file_ids_for_drive_folder(drive,folder_id_catalogos)['CatalogoSolicitudesAprobacion']\n",
    "cat_tarea_actual = (read_from_google_sheets(gc,id_catalogos_status,sheetname='CatTareaActual')\n",
    "                    .assign(tareaactual = lambda x: x.nb_tarea_actual.apply(remove_accents).str.strip().str.upper(),\n",
    "                            status_automarket = lambda x: x.status_am.apply(remove_accents).str.strip().str.upper())\n",
    "                    .drop(columns=['nb_tarea_actual','status_am'])\n",
    "                    )\n",
    "cat_decision_sistema = (read_from_google_sheets(gc,id_catalogos_status,sheetname='CatDecisionSistema')\n",
    "                      .assign(decisionsistema = lambda x: x.decisionsistema.apply(remove_accents).str.strip().str.upper(),\n",
    "                              status_riesgos = lambda x: x.riesgos.apply(remove_accents).str.strip().str.upper())\n",
    "                      .drop(columns=['riesgos'])\n",
    "                        )\n",
    "# edas, gabo, torre de control\n",
    "edas = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcEdas'])\n",
    "bauto = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcConsolidadoBautoLastStatus'])\n",
    "torreRaw = read_from_google_sheets(gc,id_torre_de_control,sheetname='Asignaci√≥n compradores')\n",
    "torreRaw.columns\n",
    "clientes = read_from_google_sheets(gc,consumo_sheets_ids_dict['AcClientes'])\n",
    "# clientes\n",
    "subset_columns = ['id_lead','origen_automarket','id_comprador','id_de_ultimo_pedido','folio_bauto',\n",
    "                  'espacio_automarket','asesor_de_ventas','fecha_de_asignacion','total_apartados',\n",
    "                  'estatus_de_lead','lead_contactado_(visualiza_cc)',\n",
    "                  'fecha_de_cierre_del_lead','motivos_de_cancelacion',\n",
    "                  'correo_recibido_en_buzon_contingencia','documentacion_completa_contingencia',\n",
    "                  ]\n",
    "rename_dict = {'lead_contactado_(visualiza_cc)':'lead_contactado'}\n",
    "torre = (torreRaw\n",
    ".pipe(process_columns)\n",
    "[subset_columns]\n",
    " .assign(folio = lambda x: pd.to_numeric(x['folio_bauto'],errors='coerce').astype('Int64'),\n",
    "         id_comprador = lambda x: pd.to_numeric(x['id_comprador'],errors='coerce').astype('Int64'),\n",
    "         fecha_de_asignacion = lambda x: pd.to_datetime(x['fecha_de_asignacion'],format='%d/%m/%Y').dt.strftime('%Y-%m-%d'),\n",
    "        #  fecha_de_cierre_del_lead = lambda x: pd.to_datetime(x['fecha_de_cierre_del_lead'],format='%d/%m/%Y').dt.strftime('%Y-%m-%d'),\n",
    "         )\n",
    " .rename(columns=rename_dict)\n",
    " .sort_values(by='fecha_de_asignacion',ascending=False)\n",
    " )\n",
    "folder_id_folios_rod = '1OW4yxE7h8BCcn0mqhCfk05B4_27Ghvfd'\n",
    "files_rod = list_file_ids_for_drive_folder(drive,folder_id_folios_rod)\n",
    "files = list(files_rod.keys())\n",
    "latest_rod_id = files_rod.get(files[0]) ## cambiar este siempre\n",
    "print(files[0])\n",
    "latest_rod_id\n",
    "from_drive_to_local(drive,latest_rod_id,'rod_latest.xlsx')\n",
    "rod = (pd.read_excel('rod_latest.xlsx')\n",
    "      .rename(columns={'Name':'intento',\n",
    "                       'MX_ATN_Id_Simulacion__c':'n_simulacion',\n",
    "                       'MX_ATN_creditId__c':'folio',\n",
    "                       'MX_ATN_Account__r.Name':'name',\n",
    "                       'MX_ATN_Account__r.MX_ATN_CommerceId__c':'id_am',\n",
    "                       'MX_ATN_Account__r.MX_ATN_PrimaryContact__r.Email':'email',\n",
    "                       'MX_ATN_Account__r.MX_ATN_PrimaryContact__r.MobilePhone':'phone',\n",
    "                       'MX_ATN_Status__c':'status'})\n",
    "      .assign(CreatedDate = lambda x: pd.to_datetime(x.CreatedDate, format=\"%d/%m/%Y, %H:%M\"),\n",
    "              phone = lambda x: x.phone.astype('Int64').astype(str))\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eaffae",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc767545",
   "metadata": {},
   "source": [
    "### folios rod by date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16486f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "bauto_mod_api = (bauto\n",
    "             .assign(flag_eda = lambda x: np.where(x.folio.isin(edas.folio.unique()),1,0),\n",
    "                     flag_tc = lambda x: np.where(x.folio.isin(torre.folio.unique()),1,0),\n",
    "                     origen_real= lambda x: np.where(x.folio.isin(edas.folio.unique()),'EDA',x.origen),\n",
    "                     decisionsistema = lambda x: x.decisionsistema.apply(remove_accents).str.strip().str.upper(),\n",
    "                     tareaactual = lambda x: x.tareaactual.apply(remove_accents).str.strip().str.upper(),\n",
    "                     telefono = lambda x: x.telefono.astype('Int64')\n",
    "                     )\n",
    "             [lambda x: x.origen_real=='API']\n",
    "             .merge(cat_tarea_actual,on='tareaactual',how='left')\n",
    "             .merge(cat_decision_sistema,on='decisionsistema',how='left')\n",
    "             .drop_duplicates()\n",
    "             .sort_values(by='fecha_creacion',ascending=False)\n",
    "             )\n",
    "\n",
    "\n",
    "dummies_status_df = pd.get_dummies(bauto_mod_api.status_automarket)*1\n",
    "dummies_status_df.columns = [f'status_automarket_{x}' for x in dummies_status_df.columns]\n",
    "bauto_mod_api = pd.concat([bauto_mod_api,dummies_status_df],axis=1)\n",
    "\n",
    "\n",
    "bauto_by_date=(bauto_mod_api\n",
    " .groupby('fecha_creacion',as_index=False)\n",
    " .agg(bauto_folios_api=('folio','nunique'),\n",
    "      bauto_folios_en_proceso = ('status_automarket_PROCESO DESEMBOLSO','sum'),\n",
    "      bauto_folios_desembolso = ('status_automarket_DESEMBOLSADO','sum'),\n",
    "      bauto_folios_rechazado = ('status_automarket_RECHAZADO','sum'),\n",
    "      bauto_folios_inicio_solicitud = ('status_automarket_INICIO SOLICITUD','sum'),\n",
    "      bauto_folios_revision_riesgo = ('status_automarket_REVISION RIESGOS','sum'),\n",
    "     \n",
    "      )\n",
    " .rename(columns={'fecha_creacion':'date'})\n",
    "\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82f8ec",
   "metadata": {},
   "source": [
    "### folios rod by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "rod_by_date = (rod\n",
    " .assign(date = lambda x:pd.to_datetime(x.CreatedDate).dt.strftime('%Y-%m-%d'),\n",
    "         id_am_con_folio = lambda x: np.where(x.folio.notna(),x.id_am,np.nan))\n",
    ".groupby('date',as_index=False)\n",
    ".agg(fapi_intentos_solicitud=('intento','nunique'),\n",
    "     fapi_usuarios_con_intento=('id_am','nunique'),\n",
    "     fapi_folios=('folio','nunique'),\n",
    "     fapi_usuarios_con_folio=('id_am_con_folio','nunique'),\n",
    "      )\n",
    " )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
